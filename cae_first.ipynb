{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "### Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 28\n",
    "SPLIT_SIZE = 4\n",
    "\n",
    "### train_x = train_x / NORMALIZE\n",
    "NORMALIZE = 1.0\n",
    "# NORMALIZE = 255   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Dataset class\n",
    "class Dataset(object) :\n",
    "    \n",
    "    def __init__(self, path, batch_size, shuffle = True, normalize = 255.0) :\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle    = shuffle\n",
    "        self.normalize  = normalize\n",
    "        self.xs, self.ys = self._load_data(path)\n",
    "        \n",
    "        self.data_size = self.xs.shape[0]\n",
    "        self.batch_max = int(math.ceil(self.data_size / float(self.batch_size)))\n",
    "        \n",
    "    def _load_data(self, path) :\n",
    "        reader = csv.reader(open(path), lineterminator = \"\\n\")\n",
    "        data   = []\n",
    "        labels = []\n",
    "        for row in reader :\n",
    "            tmp = np.asarray([float(x) for x in row])\n",
    "            \n",
    "            ### Normalize\n",
    "            tmp = tmp / self.normalize\n",
    "            \n",
    "            data.append(tmp[:INPUT_SIZE*INPUT_SIZE])\n",
    "            labels.append(tmp[INPUT_SIZE*INPUT_SIZE:])\n",
    "        \n",
    "        data   = np.asarray(data)\n",
    "        labels = np.asarray(labels)\n",
    "        return (data, labels)\n",
    "\n",
    "    def __call__(self) :\n",
    "        indexes = None\n",
    "        if self.shuffle :\n",
    "            indexes = np.random.permutation(self.data_size)\n",
    "        else :\n",
    "            indexes = np.arange(self.data_size)\n",
    "\n",
    "        for d_idx in range(self.batch_max) :\n",
    "            start =     (d_idx + 0) * self.batch_size\n",
    "            end   = min((d_idx + 1) * self.batch_size, self.data_size)\n",
    "            \n",
    "            batch_data_size = len(indexes[start:end])\n",
    "            xs = np.zeros((batch_data_size, self.xs.shape[1]), dtype = np.float32)\n",
    "            ys = np.zeros((batch_data_size, self.ys.shape[1]), dtype = np.float32)\n",
    "            \n",
    "            for b_idx, r_idx in enumerate(indexes[start:end]) :\n",
    "                xs[b_idx] = self.xs[r_idx]\n",
    "                ys[b_idx] = self.ys[r_idx]\n",
    "\n",
    "            yield (xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load dataset\n",
    "dataset = Dataset(\"training_data_4x4.csv\", 10, shuffle = True, normalize = NORMALIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_dataset = Dataset(\"training_data_4x4.csv\", 10, shuffle = False, normalize = NORMALIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load batch data sample code\n",
    "# for batch_num, (train_x, train_y) in enumerate(dataset(), 1) :\n",
    "#     print(\"Batch {0}\".format(batch_num))\n",
    "#     print(\"Train shape : {0}\".format(train_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### for jupyter, interactive session.\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer \"Conv_3/Relu:0\" shape : (?, 28, 28, 32)\n",
      "Layer \"MaxPool2D_3/MaxPool:0\" shape : (?, 14, 14, 32)\n",
      "Layer \"Conv_4/Relu:0\" shape : (?, 14, 14, 32)\n",
      "Layer \"MaxPool2D_4/MaxPool:0\" shape : (?, 7, 7, 32)\n",
      "Layer \"Conv_5/Relu:0\" shape : (?, 7, 7, 64)\n",
      "Layer \"MaxPool2D_5/MaxPool:0\" shape : (?, 4, 4, 64)\n"
     ]
    }
   ],
   "source": [
    "### Network settings\n",
    "NN_INPUT_SIZE  = INPUT_SIZE * INPUT_SIZE\n",
    "NN_OUTPUT_SIZE = 4 * SPLIT_SIZE\n",
    "\n",
    "x  = tf.placeholder(tf.float32, shape=[None, NN_INPUT_SIZE])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, NN_OUTPUT_SIZE])\n",
    "\n",
    "def print_shape(layer) :\n",
    "    print(\"Layer \\\"{0}\\\" shape : {1}\".format(layer.name, layer.shape))\n",
    "\n",
    "with slim.arg_scope([slim.conv2d, slim.fully_connected], activation_fn=tf.nn.relu,\n",
    "    weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "    biases_initializer=tf.constant_initializer(0.1)):\n",
    "    with slim.arg_scope([slim.max_pool2d], padding='SAME'):\n",
    "        x_image = slim.array_ops.reshape(x, [-1, INPUT_SIZE, INPUT_SIZE, 1])\n",
    "        h_conv1 = slim.conv2d(x_image, 32, [5, 5])\n",
    "        h_pool1 = slim.max_pool2d(h_conv1, [2, 2])\n",
    "\n",
    "        h_conv2 = slim.conv2d(h_pool1, 32, [5, 5])\n",
    "        h_pool2 = slim.max_pool2d(h_conv2, [2, 2])\n",
    "        \n",
    "        h_conv3 = slim.conv2d(h_pool2, 64, [5, 5])\n",
    "        h_pool3 = slim.max_pool2d(h_conv3, [2, 2])\n",
    "\n",
    "        h_pool3_flat = slim.flatten(h_pool3)\n",
    "        h_fc1 = slim.fully_connected(h_pool3_flat, 100)\n",
    "\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = slim.dropout(h_fc1, keep_prob)\n",
    "\n",
    "        y_out  = slim.fully_connected(h_fc1_drop, NN_OUTPUT_SIZE, activation_fn=None)\n",
    "        \n",
    "print_shape(h_conv1)\n",
    "print_shape(h_pool1)\n",
    "print_shape(h_conv2)\n",
    "print_shape(h_pool2)\n",
    "print_shape(h_conv3)\n",
    "print_shape(h_pool3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Loss\n",
    "loss = tf.losses.mean_squared_error(y_, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Training step (Optimizer)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Initialize session\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 train loss = 1798.553466796875, valid loss = 411.88538818359376, sqrt(valid loss) * 1.0 = 20.29495967435249\n",
      "Epoch 200 train loss = 1482.091259765625, valid loss = 444.4349304199219, sqrt(valid loss) * 1.0 = 21.08162542167757\n",
      "Epoch 300 train loss = 1405.4134948730468, valid loss = 224.9304458618164, sqrt(valid loss) * 1.0 = 14.997681349522546\n",
      "Epoch 400 train loss = 1263.9679748535157, valid loss = 379.33919219970704, sqrt(valid loss) * 1.0 = 19.47663195215505\n",
      "Epoch 500 train loss = 1474.6268798828125, valid loss = 357.95313720703126, sqrt(valid loss) * 1.0 = 18.919649500110495\n",
      "Epoch 600 train loss = 1408.1375366210937, valid loss = 319.88295288085936, sqrt(valid loss) * 1.0 = 17.88527195434443\n",
      "Epoch 700 train loss = 1296.4469360351563, valid loss = 322.1818023681641, sqrt(valid loss) * 1.0 = 17.9494234550351\n",
      "Epoch 800 train loss = 1398.60234375, valid loss = 306.7316360473633, sqrt(valid loss) * 1.0 = 17.513755623719412\n",
      "Epoch 900 train loss = 1350.4586181640625, valid loss = 432.6097930908203, sqrt(valid loss) * 1.0 = 20.799273859700495\n",
      "Epoch 1000 train loss = 1443.0148315429688, valid loss = 205.9888023376465, sqrt(valid loss) * 1.0 = 14.352310000053876\n",
      "Epoch 1100 train loss = 1600.3858032226562, valid loss = 290.9961822509766, sqrt(valid loss) * 1.0 = 17.05861020865934\n",
      "Epoch 1200 train loss = 1830.0967041015626, valid loss = 249.60921325683594, sqrt(valid loss) * 1.0 = 15.799025705936298\n",
      "Epoch 1300 train loss = 2118.9920288085937, valid loss = 314.8643524169922, sqrt(valid loss) * 1.0 = 17.744417500075684\n",
      "Epoch 1400 train loss = 1459.6286682128907, valid loss = 234.9730682373047, sqrt(valid loss) * 1.0 = 15.328831274343935\n",
      "Epoch 1500 train loss = 1300.5181518554687, valid loss = 495.32899169921876, sqrt(valid loss) * 1.0 = 22.255987771815896\n",
      "Epoch 1600 train loss = 1321.68681640625, valid loss = 372.0148681640625, sqrt(valid loss) * 1.0 = 19.287686957332713\n",
      "Epoch 1700 train loss = 1312.7862854003906, valid loss = 367.11310119628905, sqrt(valid loss) * 1.0 = 19.160195750468965\n",
      "Epoch 1800 train loss = 1565.9085632324218, valid loss = 302.2791229248047, sqrt(valid loss) * 1.0 = 17.386176201937122\n",
      "Epoch 1900 train loss = 1433.6976440429687, valid loss = 257.95123901367185, sqrt(valid loss) * 1.0 = 16.060860469279717\n",
      "Epoch 2000 train loss = 1570.1262817382812, valid loss = 336.20192565917966, sqrt(valid loss) * 1.0 = 18.33580992645756\n",
      "Epoch 2100 train loss = 1561.143200683594, valid loss = 345.1259140014648, sqrt(valid loss) * 1.0 = 18.577564802779314\n",
      "Epoch 2200 train loss = 1309.8565002441405, valid loss = 323.5570343017578, sqrt(valid loss) * 1.0 = 17.98769118874787\n",
      "Epoch 2300 train loss = 1430.6318481445314, valid loss = 317.72851104736327, sqrt(valid loss) * 1.0 = 17.824940702492203\n",
      "Epoch 2400 train loss = 1634.32509765625, valid loss = 300.7435821533203, sqrt(valid loss) * 1.0 = 17.34196015891284\n",
      "Epoch 2500 train loss = 1695.1337646484376, valid loss = 288.40732421875, sqrt(valid loss) * 1.0 = 16.98255941307876\n",
      "Epoch 2600 train loss = 1504.3016601562501, valid loss = 329.43282012939454, sqrt(valid loss) * 1.0 = 18.15028429885864\n",
      "Epoch 2700 train loss = 1324.5119873046874, valid loss = 274.4823486328125, sqrt(valid loss) * 1.0 = 16.56750882398475\n",
      "Epoch 2800 train loss = 1486.129931640625, valid loss = 353.2373077392578, sqrt(valid loss) * 1.0 = 18.79460847528508\n",
      "Epoch 2900 train loss = 1771.6262573242188, valid loss = 364.71337127685547, sqrt(valid loss) * 1.0 = 19.097470284748592\n",
      "Epoch 3000 train loss = 1654.170623779297, valid loss = 257.8749755859375, sqrt(valid loss) * 1.0 = 16.058486092590964\n",
      "Epoch 3100 train loss = 1511.7192260742186, valid loss = 380.34693298339846, sqrt(valid loss) * 1.0 = 19.502485302735096\n",
      "Epoch 3200 train loss = 1439.918408203125, valid loss = 375.59740753173827, sqrt(valid loss) * 1.0 = 19.380335588728546\n",
      "Epoch 3300 train loss = 1280.6995239257812, valid loss = 315.2576278686523, sqrt(valid loss) * 1.0 = 17.755495708896788\n",
      "Epoch 3400 train loss = 1507.6396057128907, valid loss = 217.6551483154297, sqrt(valid loss) * 1.0 = 14.753140286577285\n",
      "Epoch 3500 train loss = 1607.1953002929688, valid loss = 344.8498870849609, sqrt(valid loss) * 1.0 = 18.570134277515628\n",
      "Epoch 3600 train loss = 1736.9177490234374, valid loss = 452.49571533203124, sqrt(valid loss) * 1.0 = 21.27194667471765\n",
      "Epoch 3700 train loss = 1585.7443908691407, valid loss = 341.76324157714845, sqrt(valid loss) * 1.0 = 18.486839686034724\n",
      "Epoch 3800 train loss = 1519.8811279296874, valid loss = 236.1742172241211, sqrt(valid loss) * 1.0 = 15.36796073733015\n",
      "Epoch 3900 train loss = 1591.70380859375, valid loss = 478.25812377929685, sqrt(valid loss) * 1.0 = 21.869113465783126\n",
      "Epoch 4000 train loss = 1551.337744140625, valid loss = 284.9505676269531, sqrt(valid loss) * 1.0 = 16.880478892109462\n",
      "Epoch 4100 train loss = 1581.144207763672, valid loss = 290.1744049072266, sqrt(valid loss) * 1.0 = 17.034506300660038\n",
      "Epoch 4200 train loss = 1399.2341186523438, valid loss = 346.63733062744143, sqrt(valid loss) * 1.0 = 18.618198909331735\n",
      "Epoch 4300 train loss = 1434.3491455078124, valid loss = 378.7310821533203, sqrt(valid loss) * 1.0 = 19.461014417376095\n",
      "Epoch 4400 train loss = 1247.8293334960936, valid loss = 344.69510345458986, sqrt(valid loss) * 1.0 = 18.565966267732737\n",
      "Epoch 4500 train loss = 1493.3845092773438, valid loss = 351.87987060546874, sqrt(valid loss) * 1.0 = 18.758461306980077\n",
      "Epoch 4600 train loss = 1486.8526306152344, valid loss = 322.18582305908205, sqrt(valid loss) * 1.0 = 17.949535455244575\n",
      "Epoch 4700 train loss = 1398.891455078125, valid loss = 330.87352447509767, sqrt(valid loss) * 1.0 = 18.189929204785205\n",
      "Epoch 4800 train loss = 1649.2206176757813, valid loss = 399.3878875732422, sqrt(valid loss) * 1.0 = 19.984691330446967\n",
      "Epoch 4900 train loss = 1931.8915283203125, valid loss = 336.6253692626953, sqrt(valid loss) * 1.0 = 18.347353195016858\n",
      "Epoch 5000 train loss = 1681.8319091796875, valid loss = 230.64125366210936, sqrt(valid loss) * 1.0 = 15.186877679829694\n",
      "Epoch 5100 train loss = 1552.5212158203126, valid loss = 359.46107788085936, sqrt(valid loss) * 1.0 = 18.959458797150813\n",
      "Epoch 5200 train loss = 1334.4676940917968, valid loss = 378.5113189697266, sqrt(valid loss) * 1.0 = 19.455367356329372\n",
      "Epoch 5300 train loss = 1571.9711303710938, valid loss = 310.24032440185545, sqrt(valid loss) * 1.0 = 17.613640293870414\n",
      "Epoch 5400 train loss = 1457.708319091797, valid loss = 184.37928771972656, sqrt(valid loss) * 1.0 = 13.578633499720308\n",
      "Epoch 5500 train loss = 1481.7782592773438, valid loss = 250.64375, sqrt(valid loss) * 1.0 = 15.831732375201396\n",
      "Epoch 5600 train loss = 1601.8480224609377, valid loss = 360.5923187255859, sqrt(valid loss) * 1.0 = 18.98926851475817\n",
      "Epoch 5700 train loss = 1683.6320678710938, valid loss = 387.24739837646484, sqrt(valid loss) * 1.0 = 19.67860255141266\n",
      "Epoch 5800 train loss = 1618.531805419922, valid loss = 450.6897247314453, sqrt(valid loss) * 1.0 = 21.229454178839486\n",
      "Epoch 5900 train loss = 1571.3548583984375, valid loss = 306.2884262084961, sqrt(valid loss) * 1.0 = 17.501097857234445\n",
      "Epoch 6000 train loss = 1567.0699401855468, valid loss = 446.61793212890626, sqrt(valid loss) * 1.0 = 21.133336985173596\n",
      "Epoch 6100 train loss = 1784.93984375, valid loss = 320.1107574462891, sqrt(valid loss) * 1.0 = 17.891639316906907\n",
      "Epoch 6200 train loss = 1546.331103515625, valid loss = 336.2641296386719, sqrt(valid loss) * 1.0 = 18.337506091032985\n",
      "Epoch 6300 train loss = 1489.5710021972657, valid loss = 338.19634399414065, sqrt(valid loss) * 1.0 = 18.39011538827695\n",
      "Epoch 6400 train loss = 1454.4155761718748, valid loss = 341.5625961303711, sqrt(valid loss) * 1.0 = 18.481412179007616\n",
      "Epoch 6500 train loss = 1272.6561401367187, valid loss = 325.5061096191406, sqrt(valid loss) * 1.0 = 18.041787872024784\n",
      "Epoch 6600 train loss = 1962.5699340820313, valid loss = 319.876416015625, sqrt(valid loss) * 1.0 = 17.885089209048555\n",
      "Epoch 6700 train loss = 1693.70185546875, valid loss = 569.3725830078125, sqrt(valid loss) * 1.0 = 23.861529351820945\n",
      "Epoch 6800 train loss = 1602.5486572265625, valid loss = 412.7161148071289, sqrt(valid loss) * 1.0 = 20.315415693682688\n",
      "Epoch 6900 train loss = 1500.3354431152343, valid loss = 250.87505645751952, sqrt(valid loss) * 1.0 = 15.83903584368441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000 train loss = 1559.6726928710937, valid loss = 287.37750854492185, sqrt(valid loss) * 1.0 = 16.952212497043618\n",
      "Epoch 7100 train loss = 1726.553039550781, valid loss = 318.82517395019534, sqrt(valid loss) * 1.0 = 17.85567623894977\n",
      "Epoch 7200 train loss = 1559.5690185546875, valid loss = 366.10281829833986, sqrt(valid loss) * 1.0 = 19.133813480285102\n",
      "Epoch 7300 train loss = 1423.204461669922, valid loss = 363.71016998291014, sqrt(valid loss) * 1.0 = 19.07118690545793\n",
      "Epoch 7400 train loss = 1395.4330810546876, valid loss = 336.85169525146483, sqrt(valid loss) * 1.0 = 18.353519968972297\n",
      "Epoch 7500 train loss = 1590.6712890625, valid loss = 324.7494415283203, sqrt(valid loss) * 1.0 = 18.02080579575509\n",
      "Epoch 7600 train loss = 1622.0218994140625, valid loss = 356.3919418334961, sqrt(valid loss) * 1.0 = 18.87834584473693\n",
      "Epoch 7700 train loss = 1491.4078186035156, valid loss = 295.48864288330077, sqrt(valid loss) * 1.0 = 17.18978309587706\n",
      "Epoch 7800 train loss = 1474.3798095703123, valid loss = 370.5418167114258, sqrt(valid loss) * 1.0 = 19.249462764228664\n",
      "Epoch 7900 train loss = 1465.6609497070312, valid loss = 358.0578308105469, sqrt(valid loss) * 1.0 = 18.922416093367858\n",
      "Epoch 8000 train loss = 1539.2172241210938, valid loss = 485.38673095703126, sqrt(valid loss) * 1.0 = 22.031494070013302\n",
      "Epoch 8100 train loss = 1388.826953125, valid loss = 275.51320190429686, sqrt(valid loss) * 1.0 = 16.598590358952077\n",
      "Epoch 8200 train loss = 1502.3367736816406, valid loss = 282.1295471191406, sqrt(valid loss) * 1.0 = 16.796712390201264\n",
      "Epoch 8300 train loss = 1681.4849731445313, valid loss = 327.40709228515624, sqrt(valid loss) * 1.0 = 18.094393946334765\n",
      "Epoch 8400 train loss = 1615.9874633789063, valid loss = 413.3481414794922, sqrt(valid loss) * 1.0 = 20.33096508972194\n",
      "Epoch 8500 train loss = 1269.5203979492187, valid loss = 304.95078125, sqrt(valid loss) * 1.0 = 17.46284001100623\n",
      "Epoch 8600 train loss = 1895.4849121093748, valid loss = 320.5607116699219, sqrt(valid loss) * 1.0 = 17.90420932825356\n",
      "Epoch 8700 train loss = 1363.98046875, valid loss = 364.37402496337893, sqrt(valid loss) * 1.0 = 19.08858362905375\n",
      "Epoch 8800 train loss = 1738.663134765625, valid loss = 364.8291931152344, sqrt(valid loss) * 1.0 = 19.100502430963285\n",
      "Epoch 8900 train loss = 1481.0927978515624, valid loss = 324.8067428588867, sqrt(valid loss) * 1.0 = 18.022395591565697\n",
      "Epoch 9000 train loss = 1604.02451171875, valid loss = 303.34027404785155, sqrt(valid loss) * 1.0 = 17.416666559587444\n",
      "Epoch 9100 train loss = 1201.4920043945312, valid loss = 258.8676452636719, sqrt(valid loss) * 1.0 = 16.089364352381107\n",
      "Epoch 9200 train loss = 1408.0598876953125, valid loss = 319.5103515625, sqrt(valid loss) * 1.0 = 17.874852490650095\n",
      "Epoch 9300 train loss = 1645.0860473632813, valid loss = 201.93614044189454, sqrt(valid loss) * 1.0 = 14.210423654553532\n",
      "Epoch 9400 train loss = 1313.493408203125, valid loss = 306.1333831787109, sqrt(valid loss) * 1.0 = 17.4966677735708\n",
      "Epoch 9500 train loss = 1386.7408203125, valid loss = 230.3238265991211, sqrt(valid loss) * 1.0 = 15.176423379674182\n",
      "Epoch 9600 train loss = 1499.2536560058593, valid loss = 245.8475326538086, sqrt(valid loss) * 1.0 = 15.679525906538393\n",
      "Epoch 9700 train loss = 1347.1179931640625, valid loss = 414.5774353027344, sqrt(valid loss) * 1.0 = 20.3611747034088\n",
      "Epoch 9800 train loss = 1632.7695434570312, valid loss = 372.8786422729492, sqrt(valid loss) * 1.0 = 19.310065827773588\n",
      "Epoch 9900 train loss = 1665.9282592773438, valid loss = 352.44639892578124, sqrt(valid loss) * 1.0 = 18.773555841283272\n",
      "Epoch 10000 train loss = 1458.8125, valid loss = 325.56688690185547, sqrt(valid loss) * 1.0 = 18.04347214096709\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "EPOCH = 10000\n",
    "VALIDATION_EPOCH = 100\n",
    "for epoch in range(1, EPOCH + 1) :\n",
    "    \n",
    "    train_loss = 0\n",
    "    for train_x, train_y in dataset() :\n",
    "        _, tmp_loss = sess.run([train_step, loss], feed_dict = {x: train_x, y_: train_y, keep_prob: 0.5})\n",
    "        batch_loss = tmp_loss / train_x.shape[0]\n",
    "        train_loss += batch_loss\n",
    "\n",
    "    ### Validation\n",
    "    if epoch % VALIDATION_EPOCH == 0 :\n",
    "        valid_loss = 0\n",
    "        for (valid_x, valid_y) in valid_dataset() :\n",
    "            _tmp_loss  = sess.run(loss, feed_dict = {x: train_x, y_: train_y, keep_prob: 1.0})\n",
    "            batch_loss = _tmp_loss / valid_x.shape[0]\n",
    "            valid_loss += batch_loss\n",
    "        print(\"Epoch {0} train loss = {1}, valid loss = {2}, sqrt(valid loss) * {4} = {3}\".format(epoch, train_loss, valid_loss, math.sqrt(valid_loss) * NORMALIZE, NORMALIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cae_model.ckpt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Save session\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"cae_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from cae_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "### Load session\n",
    "saver.restore(sess, \"cae_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
