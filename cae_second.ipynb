{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "### Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 28\n",
    "SPLIT_SIZE = 4\n",
    "\n",
    "### train_x = train_x / NORMALIZE\n",
    "NORMALIZE = 1.0\n",
    "# NORMALIZE = 255   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Dataset class\n",
    "class Dataset(object) :\n",
    "    \n",
    "    def __init__(self, path, batch_size, shuffle = True, normalize = 255.0) :\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle    = shuffle\n",
    "        self.normalize  = normalize\n",
    "        self.xs, self.ys = self._load_data(path)\n",
    "        \n",
    "        self.data_size = self.xs.shape[0]\n",
    "        self.batch_max = int(math.ceil(self.data_size / float(self.batch_size)))\n",
    "        \n",
    "    def _load_data(self, path) :\n",
    "        reader = csv.reader(open(path), lineterminator = \"\\n\")\n",
    "        data   = []\n",
    "        labels = []\n",
    "        for row in reader :\n",
    "            tmp = np.asarray([float(x) for x in row])\n",
    "            \n",
    "            ### Normalize\n",
    "            tmp = tmp / self.normalize\n",
    "            \n",
    "            data.append(tmp[:INPUT_SIZE*INPUT_SIZE])\n",
    "            labels.append(tmp[INPUT_SIZE*INPUT_SIZE:])\n",
    "        \n",
    "        data   = np.asarray(data)\n",
    "        labels = np.asarray(labels)\n",
    "        return (data, labels)\n",
    "\n",
    "    def __call__(self) :\n",
    "        indexes = None\n",
    "        if self.shuffle :\n",
    "            indexes = np.random.permutation(self.data_size)\n",
    "        else :\n",
    "            indexes = np.arange(self.data_size)\n",
    "\n",
    "        for d_idx in range(self.batch_max) :\n",
    "            start =     (d_idx + 0) * self.batch_size\n",
    "            end   = min((d_idx + 1) * self.batch_size, self.data_size)\n",
    "            \n",
    "            batch_data_size = len(indexes[start:end])\n",
    "            xs = np.zeros((batch_data_size, self.xs.shape[1]), dtype = np.float32)\n",
    "            ys = np.zeros((batch_data_size, self.ys.shape[1]), dtype = np.float32)\n",
    "            \n",
    "            for b_idx, r_idx in enumerate(indexes[start:end]) :\n",
    "                xs[b_idx] = self.xs[r_idx]\n",
    "                ys[b_idx] = self.ys[r_idx]\n",
    "\n",
    "            yield (xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load dataset\n",
    "dataset = Dataset(\"training_data_4x4.csv\", 10, shuffle = True, normalize = NORMALIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_dataset = Dataset(\"training_data_4x4.csv\", 10, shuffle = False, normalize = NORMALIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load batch data sample code\n",
    "# for batch_num, (train_x, train_y) in enumerate(dataset(), 1) :\n",
    "#     print(\"Batch {0}\".format(batch_num))\n",
    "#     print(\"Train shape : {0}\".format(train_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### for jupyter, interactive session.\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer \"Reshape_14:0\" shape : (?, 28, 28, 1)\n",
      "Layer \"MaxPool2D_21/MaxPool:0\" shape : (?, 14, 14, 32)\n",
      "Layer \"MaxPool2D_22/MaxPool:0\" shape : (?, 7, 7, 64)\n",
      "Layer \"MaxPool2D_23/MaxPool:0\" shape : (?, 4, 4, 64)\n",
      "Layer \"Flatten_13/Reshape:0\" shape : (?, 1024)\n",
      "Layer \"Reshape_15:0\" shape : (?, 4, 4, 1)\n",
      "Layer \"Conv_32/BiasAdd:0\" shape : (?, 4, 4, 1)\n",
      "Layer \"Conv2d_transpose_6/BiasAdd:0\" shape : (?, 8, 8, 1)\n",
      "Layer \"Flatten_14/Reshape:0\" shape : (?, 16)\n"
     ]
    }
   ],
   "source": [
    "### Network settings\n",
    "NN_INPUT_SIZE  = INPUT_SIZE * INPUT_SIZE\n",
    "NN_OUTPUT_SIZE = 4 * SPLIT_SIZE\n",
    "\n",
    "### Input and Output\n",
    "x  = tf.placeholder(tf.float32, shape=[None, NN_INPUT_SIZE], name = 'data')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, NN_OUTPUT_SIZE], name = 'label')\n",
    "is_training = tf.placeholder(tf.bool, [])\n",
    "\n",
    "def print_shape(layer) :\n",
    "    print(\"Layer \\\"{0}\\\" shape : {1}\".format(layer.name, layer.shape))\n",
    "\n",
    "with slim.arg_scope([slim.conv2d, slim.fully_connected], \n",
    "                    activation_fn=tf.nn.relu, \n",
    "                    weights_initializer=tf.truncated_normal_initializer(stddev=0.1), \n",
    "                    biases_initializer=tf.constant_initializer(0.1),\n",
    "                    normalizer_fn = slim.batch_norm,\n",
    "                    normalizer_params = {'is_training': is_training},\n",
    "                   ), \\\n",
    "    slim.arg_scope([slim.max_pool2d], padding='SAME'), \\\n",
    "    slim.arg_scope([slim.conv2d_transpose], \n",
    "                   padding='SAME', \n",
    "                   activation_fn = None, \n",
    "                   stride = 2, \n",
    "                   weights_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                   normalizer_fn = slim.batch_norm,\n",
    "                   normalizer_params = {'is_training': is_training}\n",
    "                  ) :\n",
    "        \n",
    "        x_image = slim.array_ops.reshape(x, [-1, 28, 28, 1])\n",
    "        print_shape(x_image)\n",
    "        \n",
    "        ### Convolution\n",
    "        h_conv1 = slim.conv2d(x_image, 32, [3, 3])\n",
    "        h_pool1 = slim.max_pool2d(h_conv1, [2, 2])\n",
    "        print_shape(h_pool1)\n",
    "\n",
    "        h_conv2 = slim.conv2d(h_pool1, 64, [3, 3])\n",
    "        h_pool2 = slim.max_pool2d(h_conv2, [2, 2])\n",
    "        print_shape(h_pool2)\n",
    "\n",
    "        h_conv3 = slim.conv2d(h_pool2, 64, [3, 3])\n",
    "        h_pool3 = slim.max_pool2d(h_conv3, [2, 2])\n",
    "        print_shape(h_pool3)  \n",
    "\n",
    "        ### Global (fully connect)\n",
    "        h_pool3_flat = slim.flatten(h_pool3)\n",
    "        print_shape(h_pool3_flat)\n",
    "        h_pool3_fc   = slim.fully_connected(h_pool3_flat, NN_OUTPUT_SIZE, activation_fn = None, normalizer_fn = None)\n",
    "        h_pool3_reconstract = slim.array_ops.reshape(h_pool3_fc, [-1, 4, SPLIT_SIZE, 1])\n",
    "        print_shape(h_pool3_reconstract)\n",
    "        \n",
    "        ### Local (Deconvolution)\n",
    "        # h_deconv1 = slim.conv2d_transpose(h_pool3,   64, [3, 3])\n",
    "        # print_shape(h_deconv1)\n",
    "        # h_deconv2 = slim.conv2d_transpose(h_deconv1,  1, [3, 3], normalizer_fn = None)\n",
    "        # print_shape(h_deconv2)\n",
    "        # h_pool3_conv = slim.conv2d(h_pool3, 1, [3, 3], activation_fn = None, normalizer_fn = None)\n",
    "        h_pool3_conv = slim.conv2d(h_pool3, 1, [3, 3], activation_fn = None, normalizer_fn = None)\n",
    "        print_shape(h_pool3_conv)\n",
    "        \n",
    "        h_pool3_deconv = slim.conv2d_transpose(h_pool3, 1, [1, 1], activation_fn = None, normalizer_fn = None)\n",
    "        print_shape(h_pool3_deconv)\n",
    "        \n",
    "        ### Add global and local\n",
    "        # h_add = tf.add(h_pool3_reconstract, h_deconv2)\n",
    "        h_add = tf.add(h_pool3_reconstract, h_pool3_conv)\n",
    "        y_flat = slim.flatten(h_add)\n",
    "        print_shape(y_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Loss\n",
    "loss = tf.losses.mean_squared_error(y_, y_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Training step (Optimizer)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Initialize session\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 train loss = 728.0102120535713, valid loss = 793.304541015625, sqrt(valid loss) * 1.0 = 28.165662445886568\n",
      "Epoch 200 train loss = 539.0798723493303, valid loss = 560.696271623884, sqrt(valid loss) * 1.0 = 23.679025985540115\n",
      "Epoch 300 train loss = 403.5551339285715, valid loss = 431.5223458426339, sqrt(valid loss) * 1.0 = 20.773115939661867\n",
      "Epoch 400 train loss = 297.9582013811384, valid loss = 331.25888671875003, sqrt(valid loss) * 1.0 = 18.200518858503735\n",
      "Epoch 500 train loss = 218.25235770089287, valid loss = 253.10111781529014, sqrt(valid loss) * 1.0 = 15.909152014337224\n",
      "Epoch 600 train loss = 170.93891601562498, valid loss = 190.23765869140627, sqrt(valid loss) * 1.0 = 13.79266684479134\n",
      "Epoch 700 train loss = 118.62942417689733, valid loss = 143.6462637765067, sqrt(valid loss) * 1.0 = 11.985251927953232\n",
      "Epoch 800 train loss = 91.78487766810827, valid loss = 106.05640171595982, sqrt(valid loss) * 1.0 = 10.298368886185804\n",
      "Epoch 900 train loss = 64.80100446428571, valid loss = 80.58818054199219, sqrt(valid loss) * 1.0 = 8.977091986940547\n",
      "Epoch 1000 train loss = 43.80660291399274, valid loss = 60.727685546875, sqrt(valid loss) * 1.0 = 7.792797029749652\n",
      "Epoch 1100 train loss = 27.796112496512276, valid loss = 44.477183314732144, sqrt(valid loss) * 1.0 = 6.669121629924899\n",
      "Epoch 1200 train loss = 20.337203543526787, valid loss = 35.20319431849889, sqrt(valid loss) * 1.0 = 5.933227984706039\n",
      "Epoch 1300 train loss = 12.544418934413363, valid loss = 27.037025560651507, sqrt(valid loss) * 1.0 = 5.19971398835085\n",
      "Epoch 1400 train loss = 11.864626802716938, valid loss = 21.751590183803014, sqrt(valid loss) * 1.0 = 4.6638600090271805\n",
      "Epoch 1500 train loss = 7.704896436418806, valid loss = 18.26232021876744, sqrt(valid loss) * 1.0 = 4.273443601917245\n",
      "Epoch 1600 train loss = 5.276985004970006, valid loss = 14.623357500348773, sqrt(valid loss) * 1.0 = 3.8240498820424365\n",
      "Epoch 1700 train loss = 4.1925419943673266, valid loss = 12.872448921203613, sqrt(valid loss) * 1.0 = 3.5878195218270963\n",
      "Epoch 1800 train loss = 9.418306841169084, valid loss = 10.595352908543179, sqrt(valid loss) * 1.0 = 3.255050369586188\n",
      "Epoch 1900 train loss = 2.973760495867048, valid loss = 9.546615559714182, sqrt(valid loss) * 1.0 = 3.0897597899697935\n",
      "Epoch 2000 train loss = 4.128409290313721, valid loss = 11.510294124058316, sqrt(valid loss) * 1.0 = 3.392682437844473\n",
      "Epoch 2100 train loss = 3.0411571093967984, valid loss = 8.33523312977382, sqrt(valid loss) * 1.0 = 2.8870803815920714\n",
      "Epoch 2200 train loss = 1.8161545957837786, valid loss = 7.4320522308349615, sqrt(valid loss) * 1.0 = 2.726179053333614\n",
      "Epoch 2300 train loss = 1.216820512499128, valid loss = 6.524070004054479, sqrt(valid loss) * 1.0 = 2.5542259109277077\n",
      "Epoch 2400 train loss = 1.4095118250165668, valid loss = 5.986453260694232, sqrt(valid loss) * 1.0 = 2.4467229636177104\n",
      "Epoch 2500 train loss = 2.0567919186183383, valid loss = 5.513664075306484, sqrt(valid loss) * 1.0 = 2.3481192634332873\n",
      "Epoch 2600 train loss = 2.3606519426618306, valid loss = 5.185058048793247, sqrt(valid loss) * 1.0 = 2.2770722537489334\n",
      "Epoch 2700 train loss = 1.9367155143192838, valid loss = 5.11455123765128, sqrt(valid loss) * 1.0 = 2.261537361542205\n",
      "Epoch 2800 train loss = 2.2629492623465404, valid loss = 4.800962475367955, sqrt(valid loss) * 1.0 = 2.1911098729566154\n",
      "Epoch 2900 train loss = 1.5796745300292971, valid loss = 5.150416278839111, sqrt(valid loss) * 1.0 = 2.269452858915362\n",
      "Epoch 3000 train loss = 2.660778181893485, valid loss = 4.276520020621164, sqrt(valid loss) * 1.0 = 2.0679748597652643\n",
      "Epoch 3100 train loss = 1.4056966168539866, valid loss = 4.452005161557879, sqrt(valid loss) * 1.0 = 2.1099775263158325\n",
      "Epoch 3200 train loss = 1.339269651685442, valid loss = 3.6372694151742118, sqrt(valid loss) * 1.0 = 1.9071626609112846\n",
      "Epoch 3300 train loss = 1.6278549773352486, valid loss = 3.588302639552525, sqrt(valid loss) * 1.0 = 1.8942815629025493\n",
      "Epoch 3400 train loss = 0.8908255611147199, valid loss = 3.190289810725621, sqrt(valid loss) * 1.0 = 1.786138239534001\n",
      "Epoch 3500 train loss = 1.1641999380929131, valid loss = 3.5303362097058977, sqrt(valid loss) * 1.0 = 1.8789188938604822\n",
      "Epoch 3600 train loss = 0.8332042217254639, valid loss = 2.5588700498853414, sqrt(valid loss) * 1.0 = 1.5996468516161126\n",
      "Epoch 3700 train loss = 0.7965628692081997, valid loss = 2.6559439590999054, sqrt(valid loss) * 1.0 = 1.6297067095339288\n",
      "Epoch 3800 train loss = 1.0355790546962194, valid loss = 2.6091046639851165, sqrt(valid loss) * 1.0 = 1.615272318832065\n",
      "Epoch 3900 train loss = 0.5698504107339042, valid loss = 2.438539505004883, sqrt(valid loss) * 1.0 = 1.561582372148483\n",
      "Epoch 4000 train loss = 1.7350697313036236, valid loss = 2.2572680950164794, sqrt(valid loss) * 1.0 = 1.5024207450033693\n",
      "Epoch 4100 train loss = 2.2689368384225026, valid loss = 2.2554517473493303, sqrt(valid loss) * 1.0 = 1.5018161496499265\n",
      "Epoch 4200 train loss = 0.4986703225544521, valid loss = 2.576892389569964, sqrt(valid loss) * 1.0 = 1.6052701920766996\n",
      "Epoch 4300 train loss = 0.6665771654673984, valid loss = 2.1141191482543946, sqrt(valid loss) * 1.0 = 1.454001082618027\n",
      "Epoch 4400 train loss = 0.7071489436285836, valid loss = 2.2399060249328615, sqrt(valid loss) * 1.0 = 1.4966315595138509\n",
      "Epoch 4500 train loss = 0.95885123865945, valid loss = 1.9083322150366648, sqrt(valid loss) * 1.0 = 1.3814239809112425\n",
      "Epoch 4600 train loss = 0.8880070856639317, valid loss = 2.6776481321879797, sqrt(valid loss) * 1.0 = 1.6363520807540104\n",
      "Epoch 4700 train loss = 0.738906809261867, valid loss = 2.0698936121804374, sqrt(valid loss) * 1.0 = 1.4387124841956567\n",
      "Epoch 4800 train loss = 0.680179500579834, valid loss = 1.981182483264378, sqrt(valid loss) * 1.0 = 1.4075448423636023\n",
      "Epoch 4900 train loss = 0.753965071269444, valid loss = 1.8317344495228358, sqrt(valid loss) * 1.0 = 1.353415845009521\n",
      "Epoch 5000 train loss = 0.4707612003598895, valid loss = 1.743742799758911, sqrt(valid loss) * 1.0 = 1.3205085383135207\n",
      "Epoch 5100 train loss = 0.788322469166347, valid loss = 1.6195735829217095, sqrt(valid loss) * 1.0 = 1.2726246826624532\n",
      "Epoch 5200 train loss = 0.44650657517569403, valid loss = 1.6888592209134783, sqrt(valid loss) * 1.0 = 1.2995611647450374\n",
      "Epoch 5300 train loss = 0.6198874303272792, valid loss = 1.6610898835318426, sqrt(valid loss) * 1.0 = 1.2888327601096439\n",
      "Epoch 5400 train loss = 0.7428680385862079, valid loss = 1.604383179119655, sqrt(valid loss) * 1.0 = 1.2666424827549623\n",
      "Epoch 5500 train loss = 0.4385069012641906, valid loss = 1.6365416186196462, sqrt(valid loss) * 1.0 = 1.2792738638069825\n",
      "Epoch 5600 train loss = 0.9852463858468192, valid loss = 1.4837101936340333, sqrt(valid loss) * 1.0 = 1.2180764317702044\n",
      "Epoch 5700 train loss = 0.4972606727055141, valid loss = 1.4464941910334996, sqrt(valid loss) * 1.0 = 1.2027028689720083\n",
      "Epoch 5800 train loss = 0.3725788678441729, valid loss = 1.2705678599221366, sqrt(valid loss) * 1.0 = 1.1271946859004156\n",
      "Epoch 5900 train loss = 0.468726430620466, valid loss = 1.3117305210658483, sqrt(valid loss) * 1.0 = 1.1453080463638803\n",
      "Epoch 6000 train loss = 0.4857857363564627, valid loss = 1.3844203489167348, sqrt(valid loss) * 1.0 = 1.1766139336743955\n",
      "Epoch 6100 train loss = 0.4204163994107928, valid loss = 1.312577554157802, sqrt(valid loss) * 1.0 = 1.1456777706483625\n",
      "Epoch 6200 train loss = 0.26515957968575615, valid loss = 1.1876672165734428, sqrt(valid loss) * 1.0 = 1.0898014574102215\n",
      "Epoch 6300 train loss = 0.39882294450487416, valid loss = 1.2056642668587823, sqrt(valid loss) * 1.0 = 1.0980274435817996\n",
      "Epoch 6400 train loss = 0.5418366023472377, valid loss = 1.3731769698006766, sqrt(valid loss) * 1.0 = 1.171826339438006\n",
      "Epoch 6500 train loss = 0.41925388404301234, valid loss = 1.0651481764657158, sqrt(valid loss) * 1.0 = 1.0320601612627607\n",
      "Epoch 6600 train loss = 0.3848473651068551, valid loss = 1.2620191778455463, sqrt(valid loss) * 1.0 = 1.1233962692859303\n",
      "Epoch 6700 train loss = 0.47618304320744104, valid loss = 1.1269881776400974, sqrt(valid loss) * 1.0 = 1.0615969939859935\n",
      "Epoch 6800 train loss = 0.36384701388222834, valid loss = 1.133942655154637, sqrt(valid loss) * 1.0 = 1.0648674354841718\n",
      "Epoch 6900 train loss = 0.5046404089246478, valid loss = 0.950167042868478, sqrt(valid loss) * 1.0 = 0.9747651218978232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000 train loss = 0.3995631166866847, valid loss = 1.104120741571699, sqrt(valid loss) * 1.0 = 1.050771498267677\n",
      "Epoch 7100 train loss = 0.3304118905748639, valid loss = 1.2163497516087123, sqrt(valid loss) * 1.0 = 1.1028824740690697\n",
      "Epoch 7200 train loss = 0.4726739849363054, valid loss = 1.2196226716041565, sqrt(valid loss) * 1.0 = 1.1043652799704256\n",
      "Epoch 7300 train loss = 0.3109609433582851, valid loss = 1.0693596363067628, sqrt(valid loss) * 1.0 = 1.034098465479358\n",
      "Epoch 7400 train loss = 0.35304806402751376, valid loss = 0.9392268589564733, sqrt(valid loss) * 1.0 = 0.9691371724149649\n",
      "Epoch 7500 train loss = 0.37337128434862404, valid loss = 1.0170026847294398, sqrt(valid loss) * 1.0 = 1.008465509935486\n",
      "Epoch 7600 train loss = 0.3360155020441328, valid loss = 1.017811301776341, sqrt(valid loss) * 1.0 = 1.0088663448526476\n",
      "Epoch 7700 train loss = 0.2534714494432722, valid loss = 1.1379922253744943, sqrt(valid loss) * 1.0 = 1.0667671842414794\n",
      "Epoch 7800 train loss = 0.3988175562449864, valid loss = 0.9550208057676043, sqrt(valid loss) * 1.0 = 0.9772516593833976\n",
      "Epoch 7900 train loss = 0.36259860311235703, valid loss = 0.9599258456911359, sqrt(valid loss) * 1.0 = 0.9797580546702007\n",
      "Epoch 8000 train loss = 0.2568135227475848, valid loss = 0.961037414414542, sqrt(valid loss) * 1.0 = 0.9803251574934421\n",
      "Epoch 8100 train loss = 0.25562327248709543, valid loss = 0.7920952694756644, sqrt(valid loss) * 1.0 = 0.8899973423980908\n",
      "Epoch 8200 train loss = 0.26738408293042865, valid loss = 0.86384231703622, sqrt(valid loss) * 1.0 = 0.9294311792899032\n",
      "Epoch 8300 train loss = 0.3082811985697065, valid loss = 0.8996223637035915, sqrt(valid loss) * 1.0 = 0.948484245363934\n",
      "Epoch 8400 train loss = 0.33256037916455955, valid loss = 0.9767540999821254, sqrt(valid loss) * 1.0 = 0.9883087068229872\n",
      "Epoch 8500 train loss = 0.3741669365337917, valid loss = 0.6953685147421701, sqrt(valid loss) * 1.0 = 0.8338875911909052\n",
      "Epoch 8600 train loss = 0.22664272274289815, valid loss = 0.7000229307583401, sqrt(valid loss) * 1.0 = 0.8366737301710506\n",
      "Epoch 8700 train loss = 0.2062492787837982, valid loss = 0.803802980695452, sqrt(valid loss) * 1.0 = 0.8965506013022645\n",
      "Epoch 8800 train loss = 0.38692357369831626, valid loss = 0.892816994871412, sqrt(valid loss) * 1.0 = 0.9448899379670692\n",
      "Epoch 8900 train loss = 0.2034523436001369, valid loss = 0.7214536871228899, sqrt(valid loss) * 1.0 = 0.8493842988441038\n",
      "Epoch 9000 train loss = 0.17888466971261163, valid loss = 0.8687520435878209, sqrt(valid loss) * 1.0 = 0.9320686903806076\n",
      "Epoch 9100 train loss = 1.091853882585253, valid loss = 0.8982725960867745, sqrt(valid loss) * 1.0 = 0.9477724389782467\n",
      "Epoch 9200 train loss = 0.26879571080207826, valid loss = 0.7053726162229266, sqrt(valid loss) * 1.0 = 0.8398646416077573\n",
      "Epoch 9300 train loss = 0.23478226831981114, valid loss = 0.7961339780262539, sqrt(valid loss) * 1.0 = 0.8922634017072839\n",
      "Epoch 9400 train loss = 0.19597937294415063, valid loss = 0.7315107754298619, sqrt(valid loss) * 1.0 = 0.8552840320208615\n",
      "Epoch 9500 train loss = 0.22888862405504498, valid loss = 0.7004171763147626, sqrt(valid loss) * 1.0 = 0.83690929993325\n",
      "Epoch 9600 train loss = 0.2748611620494298, valid loss = 0.7620436753545489, sqrt(valid loss) * 1.0 = 0.872951129992137\n",
      "Epoch 9700 train loss = 0.28978700126920426, valid loss = 0.6967509576252529, sqrt(valid loss) * 1.0 = 0.8347160940255393\n",
      "Epoch 9800 train loss = 0.2364914553506034, valid loss = 0.8537188427788871, sqrt(valid loss) * 1.0 = 0.9239690702501286\n",
      "Epoch 9900 train loss = 0.234335458278656, valid loss = 0.6128653117588588, sqrt(valid loss) * 1.0 = 0.7828571464570396\n",
      "Epoch 10000 train loss = 0.19464119587625775, valid loss = 0.6977663942745753, sqrt(valid loss) * 1.0 = 0.8353241252798672\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "EPOCH = 10000\n",
    "VALIDATION_EPOCH = 100\n",
    "for epoch in range(1, EPOCH + 1) :\n",
    "    \n",
    "    train_loss  = 0\n",
    "    train_count = 0\n",
    "    for train_x, train_y in dataset() :\n",
    "        train_count += 1\n",
    "        _, tmp_loss = sess.run([train_step, loss], feed_dict = {x: train_x, y_: train_y, is_training: True})\n",
    "        batch_loss = tmp_loss / train_x.shape[0]\n",
    "        train_loss += batch_loss\n",
    "    if train_count > 0 :\n",
    "        train_loss /= train_count\n",
    "\n",
    "    ### Validation\n",
    "    if epoch % VALIDATION_EPOCH == 0 :\n",
    "        valid_loss  = 0\n",
    "        valid_count = 0\n",
    "        for (valid_x, valid_y) in valid_dataset() :\n",
    "            valid_count += 1\n",
    "            tmp_loss   = sess.run(loss, feed_dict = {x: valid_x, y_: valid_y, is_training: True}) # 本当は is_training = False!!\n",
    "            batch_loss = tmp_loss / valid_x.shape[0]\n",
    "            valid_loss += batch_loss\n",
    "        if valid_count > 0 :\n",
    "            valid_loss /= valid_count\n",
    "        print(\"Epoch {0} train loss = {1}, valid loss = {2}, sqrt(valid loss) * {4} = {3}\".format(epoch, train_loss, valid_loss, math.sqrt(valid_loss) * NORMALIZE, NORMALIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cae_model.ckpt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Save session\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"cae_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from cae_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "### Load session\n",
    "saver.restore(sess, \"cae_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
